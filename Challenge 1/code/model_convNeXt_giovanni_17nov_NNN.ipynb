{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"rvTNBChjFgvH"},"outputs":[],"source":["\"\"\" from google.colab import drive\n","drive.mount('/gdrive')\n","%cd /gdrive/My Drive/AN2DL/Challenge 1/NoNutNet \"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CHVSMBgVFiZY"},"outputs":[],"source":["\n","import os\n","\n","#Fix randomness and hide warnings\n","seed = 69420\n","\n","import os\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n","os.environ['PYTHONHASHSEED'] = str(seed)\n","os.environ['MPLCONFIGDIR'] = os.getcwd()+'/configs/'\n","\n","import warnings\n","warnings.simplefilter(action='ignore', category=FutureWarning)\n","warnings.simplefilter(action='ignore', category=Warning)\n","\n","import numpy as np\n","np.random.seed(seed)\n","\n","import logging\n","\n","import random\n","random.seed(seed)\n","\n","# Import tensorflow\n","import tensorflow as tf\n","from tensorflow import keras as tfk\n","from tensorflow.keras import layers as tfkl\n","from tensorflow.keras.applications.mobilenet import preprocess_input\n","tf.autograph.set_verbosity(0)\n","tf.get_logger().setLevel(logging.ERROR)\n","tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n","tf.random.set_seed(seed)\n","tf.compat.v1.set_random_seed(seed)\n","#print(tf.__version__)\n","\n","# Import other libraries\n","#import cv2\n","#from tensorflow.keras.applications.mobilenet import preprocess_input\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n","import seaborn as sns\n","\n","from sklearn.preprocessing import LabelEncoder\n","\n","print(\"Finished loading libraries\")\n","\n","model_name = \"model_convNeXt_giovanni_17nov_NNN\"\n","\n","class model:\n","    def __init__(self, path):\n","        self.model = tf.keras.models.load_model(os.path.join(path, model_name))\n","\n","    def predict(self, X):\n","\n","        # Note: this is just an example.\n","        # Here the model.predict is called, followed by the argmax\n","        out = self.model.predict(X)\n","        out = tf.argmax(out, axis=-1)  # Shape [BS]\n","\n","        return out\n","\n","\n","def show_images(images):\n","    # Show all images in in images array. Make a scrollable window if there are more than 50 images and display them in a grid\n","    num_images = len(images)    # Number of images\n","    num_cols = int(np.ceil(np.sqrt(num_images)))    # Number of columns in the grid\n","    num_rows = int(np.ceil(num_images / num_cols))\n","\n","    for i in range(num_images):\n","        plt.subplot(num_rows, num_cols, i+1)\n","        plt.imshow(images[i])\n","        plt.axis('off')\n","    plt.show()\n","\n","def plot_results(history):\n","    \"\"\" print(\"Plotting results...\")\n","    # Plot the training\n","    plt.figure(figsize=(15,5))\n","    plt.plot(history['loss'], alpha=.3, color='#ff7f0e', linestyle='--')\n","    plt.plot(history['val_loss'], label='Vanilla CNN', alpha=.8, color='#ff7f0e')\n","    plt.legend(loc='upper left')\n","    plt.title('Categorical Crossentropy')\n","    plt.grid(alpha=.3)\n","\n","    plt.figure(figsize=(15,5))\n","    plt.plot(history['accuracy'], alpha=.3, color='#ff7f0e', linestyle='--')\n","    plt.plot(history['val_accuracy'], label='Vanilla CNN', alpha=.8, color='#ff7f0e')\n","    plt.legend(loc='upper left')\n","    plt.title('Accuracy')\n","    plt.grid(alpha=.3)\n","\n","    plt.show() \"\"\"\n","\n","    # Find the epoch with the highest validation accuracy\n","    best_epoch = np.argmax(history['val_accuracy'])\n","\n","    # Plot training and validation performance metrics\n","    plt.figure(figsize=(20, 5))\n","\n","    # Plot training and validation loss\n","    plt.plot(history['loss'], label='Training', alpha=0.8, color='#ff7f0e', linewidth=3)\n","    plt.plot(history['val_loss'], label='Validation', alpha=0.8, color='#4D61E2', linewidth=3)\n","    plt.legend(loc='upper left')\n","    plt.title('Categorical Crossentropy')\n","    plt.grid(alpha=0.3)\n","\n","    plt.figure(figsize=(20, 5))\n","\n","    # Plot training and validation accuracy, highlighting the best epoch\n","    plt.plot(history['accuracy'], label='Training', alpha=0.8, color='#ff7f0e', linewidth=3)\n","    plt.plot(history['val_accuracy'], label='Validation', alpha=0.8, color='#4D61E2', linewidth=3)\n","    plt.plot(best_epoch, history['val_accuracy'][best_epoch], marker='*', alpha=0.8, markersize=10, color='#4D61E2')\n","    plt.legend(loc='upper left')\n","    plt.title('Accuracy')\n","    plt.grid(alpha=0.3)\n","\n","    plt.show()\n","\n","\n","def train_model():\n","    print(\"[*] Training model \", model_name, \"...\")\n","    # Load images from the .npz file\n","    data_path = 'public_data.npz'\n","    data = np.load(data_path, allow_pickle=True)\n","\n","    images = data['data']\n","    labels = data['labels']\n","\n","    \"\"\" i = 0\n","    for image in images:\n","        # Normalize image pixel values to a float range [0, 1]\n","        #images[i] = (images[i] / 255).astype(np.float32)\n","\n","        # Convert image from BGR to RGB\n","        #images[i] = images[i][...,::-1]\n","        i = i+1\n","        if (i % 1000 == 0):\n","            print(\"Processing image: \", i)\n","    print(\"Finished processing images\") \"\"\"\n","    # EfficientNetV2 models expect their inputs to be float tensors of pixels with values in the [0-255] range.\n","    images = (images).astype(np.float32)\n","\n","    # ------------------------------------------\n","    # Sanitize input\n","    # Delete trolololol and shrek\n","    positions_to_remove_old = [58, 95, 137, 138, 171, 207, 338, 412, 434, 486, 506, 529, 571,\n","                           599, 622, 658, 692, 701, 723, 725, 753, 779, 783, 827, 840, 880,\n","                           898, 901, 961, 971, 974, 989, 1028, 1044, 1064, 1065, 1101, 1149,\n","                           1172, 1190, 1191, 1265, 1268, 1280, 1333, 1384, 1443, 1466, 1483,\n","                           1528, 1541, 1554, 1594, 1609, 1630, 1651, 1690, 1697, 1752, 1757,\n","                           1759, 1806, 1828, 1866, 1903, 1938, 1939, 1977, 1981, 1988, 2022,\n","                           2081, 2090, 2150, 2191, 2192, 2198, 2261, 2311, 2328, 2348, 2380,\n","                           2426, 2435, 2451, 2453, 2487, 2496, 2515, 2564, 2581, 2593, 2596,\n","                           2663, 2665, 2675, 2676, 2727, 2734, 2736, 2755, 2779, 2796, 2800,\n","                           2830, 2831, 2839, 2864, 2866, 2889, 2913, 2929, 2937, 3033, 3049,\n","                           3055, 3086, 3105, 3108, 3144, 3155, 3286, 3376, 3410, 3436, 3451,\n","                           3488, 3490, 3572, 3583, 3666, 3688, 3700, 3740, 3770, 3800, 3801,\n","                           3802, 3806, 3811, 3821, 3835, 3862, 3885, 3896, 3899, 3904, 3927,\n","                           3931, 3946, 3950, 3964, 3988, 3989, 4049, 4055, 4097, 4100, 4118,\n","                           4144, 4150, 4282, 4310, 4314, 4316, 4368, 4411, 4475, 4476, 4503,\n","                           4507, 4557, 4605, 4618, 4694, 4719, 4735, 4740, 4766, 4779, 4837,\n","                           4848, 4857, 4860, 4883, 4897, 4903, 4907, 4927, 5048, 5080, 5082,\n","                           5121, 5143, 5165, 5171]\n","    def mse(imageA, imageB):\n","        # the 'Mean Squared Error' between the two images is the\n","        # sum of the squared difference between the two images;\n","        # NOTE: the two images must have the same dimension\n","        err = np.sum((imageA.astype(\"float\") - imageB.astype(\"float\")) ** 2)\n","        err /= float(imageA.shape[0] * imageA.shape[1])\n","\n","        # return the MSE, the lower the error, the more \"similar\"\n","        # the two images are\n","        return err\n","    positions_to_remove = []\n","\n","    pos_shrek = 58\n","    pos_trolo = 338\n","    for pos in range(len(images)):\n","        if (mse(images[pos_shrek],images[pos])==0 or mse(images[pos_trolo],images[pos])==0):\n","            positions_to_remove.append(pos)\n","    if (positions_to_remove != positions_to_remove_old):\n","        print(\"ERROR: Different positions to remove\")\n","        exit()\n","    print(\"Len of positions_to_remove: \", len(positions_to_remove))\n","    n = 0\n","\n","    for pos in positions_to_remove:\n","        new_pos = pos - n\n","        #print(\"Removing image at position: \", pos, \" - New Position is \", new_pos)\n","        images = np.delete(images, new_pos, axis=0)\n","        labels = np.delete(labels, new_pos, axis=0)\n","        n = n + 1\n","\n","    # ------------------------------------------\n","\n","    labels = np.array(labels)\n","\n","    labels = LabelEncoder().fit_transform(labels)\n","    labels = tfk.utils.to_categorical(labels,len(np.unique(labels)))\n","\n","    # Use the stratify option to maintain the class distribution in the train and test datasets\n","    images_train, images_test, labels_train, labels_test = train_test_split(images, labels, test_size=0.15, stratify=np.argmax(labels, axis=1), random_state=seed)\n","\n","    # Further split the test set into test and validation sets, stratifying the labels\n","    images_test, images_val, labels_test, labels_val = train_test_split(images_test, labels_test, test_size=0.9, stratify=np.argmax(labels_test, axis=1), random_state=seed)\n","\n","    print(\"\\n\\nSHAPES OF THE SETS:\\n\")\n","\n","    print(f\"images_train shape: {images_train.shape}, labels_train shape: {labels_train.shape}\")\n","    print(f\"images_val shape: {images_val.shape}, labels_val shape: {labels_val.shape}\")\n","    print(f\"images_test shape: {images_test.shape}, labels_test shape: {labels_test.shape}\")\n","\n","    print(\"\\n\\n\")\n","\n","    input_shape = images_train.shape[1:]\n","    output_shape = labels_train.shape[1:]\n","\n","    # ------------------------------------------\n","    #Print input shape, batch size, and number of epochs\n","    #print(f\"Input Shape: {input_shape}, Output Shape: {output_shape}, Batch Size: {batch_size}, Epochs: {epochs}\")\n","    # ------------------------------------------\n","    #if include_preprocessing=True no preprocessing is needed\n","    \"\"\" efficientNet = tf.keras.applications.EfficientNetV2L(\n","        include_top=False,\n","        weights=\"imagenet\",\n","        input_shape=input_shape,\n","        pooling=None,\n","        include_preprocessing=True,\n","    ) \"\"\"\n","\n","    externalNet = tf.keras.applications.ConvNeXtLarge(\n","        model_name=\"convnext_large\",\n","        include_top=False,\n","        include_preprocessing=True,\n","        weights=\"imagenet\",\n","        #input_tensor=None,\n","        input_shape=input_shape,\n","        pooling=\"avg\",\n","        #classes=1000,\n","        #classifier_activation=\"softmax\",\n","    )\n","\n","    #Automatically get the name of the network\n","    network_keras_name = externalNet.name\n","    print(\"[*] Network name: \", network_keras_name)\n","\n","    \"\"\"mobile = tf.keras.applications.MobileNetV3Large(\n","        input_shape=None,\n","        alpha=1.0,\n","        minimalistic=False,\n","        include_top=True,\n","        weights=\"imagenet\",\n","        input_tensor=None,\n","        classes=1000,\n","        pooling=None,\n","        dropout_rate=0.2,\n","        classifier_activation=\"softmax\",\n","        include_preprocessing=True,\n","    )\"\"\"\n","\n","    for i, layer in enumerate(externalNet.layers):\n","        print(i, layer.name, layer.trainable)\n","\n","    #tfk.utils.plot_model(mobile, show_shapes=True)\n","    # Use the supernet as feature extractor, i.e. freeze all its weigths\n","    externalNet.trainable = False\n","\n","    # Create an input layer with shape (224, 224, 3)\n","    inputs = tfk.Input(shape=(96, 96, 3))\n","\n","    augmentation = tf.keras.Sequential([\n","            #tfkl.RandomBrightness(0.2, value_range=(0,1)),\n","            tfkl.RandomTranslation(0.15,0.15),\n","            #tfkl.RandomContrast(0.75),\n","            #tfkl.RandomBrightness(0.15),\n","            tfkl.RandomZoom(0.1),\n","            tfkl.RandomFlip(\"horizontal\"),\n","            tfkl.RandomFlip(\"vertical\"),\n","            tfkl.RandomRotation(0.2),\n","        ], name='preprocessing')\n","\n","    augmentation = augmentation(inputs)\n","\n","    #not needed\n","    #scale_layer = tfkl.Rescaling(scale = 1/127.5, offset = -1)\n","    #x = scale_layer(augmentation)\n","\n","    #x = mobile(augmentation)\n","    x = externalNet(augmentation)\n","\n","    \"\"\" x = tfkl.Conv2D (\n","        filters = 128,\n","        kernel_size = (3,3),\n","        activation = 'relu',\n","        name = 'Conv2D_1'\n","    ) (x) \"\"\"\n","\n","    #x = tfkl.GlobalAveragePooling2D()(x)\n","\n","    x = tfkl.Dropout(0.5)(x)\n","\n","    reg_strength = 0.04\n","    outputs = tfkl.Dense(\n","            2,\n","            kernel_regularizer=tfk.regularizers.l2(reg_strength),\n","            activation='softmax',\n","            name='Output'\n","        )(x)\n","\n","\n","    # Create a Model connecting input and output\n","    tl_model = tfk.Model(inputs=inputs, outputs=outputs, name='model')\n","\n","    # Compile the model with Categorical Cross-Entropy loss and Adam optimizer\n","    tl_model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(), metrics=['accuracy'])\n","\n","    # Display model summary\n","    tl_model.summary()\n","    # Train the model\n","    tl_history = tl_model.fit(\n","        x = images_train, # We need to apply the preprocessing thought for the MobileNetV2 network\n","        y = labels_train,\n","        batch_size = 32,\n","        epochs = 200,\n","        validation_data = (images_val, labels_val), # We need to apply the preprocessing thought for the MobileNetV2 network\n","        callbacks = [tfk.callbacks.EarlyStopping(monitor='val_accuracy', mode='max', patience=20, restore_best_weights=True)]\n","    ).history\n","\n","    # Save the best model\n","    tl_model.save('TransferLearningModel')\n","    del tl_model\n","\n","    # Re-load the model after transfer learning\n","    ft_model = tfk.models.load_model('TransferLearningModel')\n","    ft_model.summary()\n","\n","    # Set all MobileNetV2 layers as trainable\n","    ft_model.get_layer(network_keras_name).trainable = True\n","    #for i, layer in enumerate(ft_model.get_layer('mobilenetv2_1.00_96').layers):\n","    #    print(i, layer.name, layer.trainable)\n","\n","    # Freeze first N layers, e.g., until the 133rd one\n","    #N = 270\n","    N = 125\n","    for i, layer in enumerate(ft_model.get_layer(network_keras_name).layers[:N]):\n","        layer.trainable=False\n","    for i, layer in enumerate(ft_model.get_layer(network_keras_name).layers):\n","        print(i, layer.name, layer.trainable)\n","    ft_model.summary()\n","\n","    # Compile the model\n","    ft_model.compile(loss=tfk.losses.BinaryCrossentropy(), optimizer=tfk.optimizers.Adam(1e-5), metrics='accuracy')\n","\n","    # Fine-tune the model\n","    ft_history = ft_model.fit(\n","        x = images_train, # We need to apply the preprocessing thought for the MobileNetV2 network\n","        y = labels_train,\n","        batch_size = 32,\n","        epochs = 200,\n","        validation_data = (images_val, labels_val), # We need to apply the preprocessing thought for the MobileNetV2 network\n","        callbacks = [tfk.callbacks.EarlyStopping(monitor='val_accuracy', mode='max', patience=20, restore_best_weights=True)]\n","    ).history\n","\n","    # Save the model\n","    ft_model.save(model_name)\n","\n","    # ------------------------------------------\n","    plot_result = True\n","    if plot_result:\n","        plot_results(ft_history)\n","    # ------------------------------------------\n","\n","    evaluate = True\n","    if evaluate:\n","        # Evaluate the model on the test set\n","        # Copilot generated version:\n","        # test_loss, test_acc = model.evaluate(images_test, labels_test, verbose=2)\n","\n","        # Notebooks version:\n","        # Predict labels for the entire test set\n","        predictions = ft_model.predict(images_test, verbose=0)\n","\n","        # Display the shape of the predictions\n","        print(\"Predictions Shape:\", predictions.shape)\n","\n","        # Compute the confusion matrix\n","        cm = confusion_matrix(np.argmax(labels_test, axis=-1), np.argmax(predictions, axis=-1))\n","\n","        # Compute classification metrics\n","        accuracy = accuracy_score(np.argmax(labels_test, axis=-1), np.argmax(predictions, axis=-1))\n","        precision = precision_score(np.argmax(labels_test, axis=-1), np.argmax(predictions, axis=-1), average='macro')\n","        recall = recall_score(np.argmax(labels_test, axis=-1), np.argmax(predictions, axis=-1), average='macro')\n","        f1 = f1_score(np.argmax(labels_test, axis=-1), np.argmax(predictions, axis=-1), average='macro')\n","\n","        # Display the computed metrics\n","        print('Accuracy:', accuracy.round(4))\n","        print('Precision:', precision.round(4))\n","        print('Recall:', recall.round(4))\n","        print('F1:', f1.round(4))\n","\n","        #print(\"\\n0:Healthy, 1:Unhealthy\\n\")\n","        # Plot the confusion matrix\n","        plt.figure(figsize=(10, 8))\n","        sns.heatmap(cm.T, annot=True, xticklabels=np.unique(labels_test), yticklabels=np.unique(labels_test), cmap='Blues')\n","        plt.xlabel('True labels')\n","        plt.ylabel('Predicted labels')\n","        plt.show()\n","\n","# ------------------------------------------\n","if __name__ == \"__main__\":\n","    train = True\n","    if (train):\n","        train_model()\n","    else:\n","        print(\"No training :(\")\n","    #_model = model(os.getcwd())\n","\n","    \"\"\" # Load images from the .npz file\n","    __data_path = 'Challenge 1/data/phase_1/public_data.npz'\n","    __data = np.load(__data_path, allow_pickle=True)\n","\n","    __images = __data['data']\n","    __labels = __data['labels']\n","\n","    i = 0\n","    for __image in __images:\n","        # Normalize image pixel values to a float range [0, 1]\n","        __images[i] = (__images[i] / 255).astype(np.float32)\n","        # Convert image from BGR to RGB\n","        __images[i] = __images[i][...,::-1]\n","        if (i % 100 == 0):\n","            print(\"Processing image: \", i, \"\\n\")\n","            #pred = _model.predict(__image)\n","            #print(\"Prediction: \", pred, \" - Label: \", __labels[i])\n","        i = i+1\n","\n","    # print the shape of __images\n","    print(__images.shape)\n","\n","    pred = _model.predict(__images)\n","    print(pred)\n","\n","    for y in pred:\n","        print(y, \"\\n\") \"\"\"\n","\n","    print(\"Done!\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ryWZ-uBlFiM6"},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyN/grZKiwZQPNgfLQHsbQzo","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
